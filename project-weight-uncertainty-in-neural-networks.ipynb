{"metadata":{"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.11.11"},"kaggle":{"accelerator":"gpu","dataSources":[],"dockerImageVersionId":31041,"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":true},"papermill":{"default_parameters":{},"duration":10686.184822,"end_time":"2025-05-26T13:55:59.779577","environment_variables":{},"exception":null,"input_path":"__notebook__.ipynb","output_path":"__notebook__.ipynb","parameters":{},"start_time":"2025-05-26T10:57:53.594755","version":"2.6.0"}},"nbformat_minor":5,"nbformat":4,"cells":[{"id":"b45e34b0","cell_type":"markdown","source":"# [ASI Project] Weight Uncertainty in Neural Networks  \n**Authors**: Miriam Lamari, Francesco Giannuzzo  \n","metadata":{"papermill":{"duration":0.003798,"end_time":"2025-05-26T10:57:57.647088","exception":false,"start_time":"2025-05-26T10:57:57.643290","status":"completed"},"tags":[]}},{"id":"027168fc","cell_type":"code","source":"import csv\nimport math\nimport functools as ft\nfrom typing import Any, Optional\n\nimport numpy as np\nimport torch\nimport torch.nn as nn\nimport torch.nn.functional as F\nfrom torch import Tensor\nfrom torch.utils.data import DataLoader, random_split\nfrom torchvision import datasets, transforms\nfrom kaggle_secrets import UserSecretsClient\nimport wandb\n","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:11.238548Z","iopub.execute_input":"2025-06-10T08:33:11.239018Z","iopub.status.idle":"2025-06-10T08:33:22.658439Z","shell.execute_reply.started":"2025-06-10T08:33:11.238989Z","shell.execute_reply":"2025-06-10T08:33:22.657658Z"},"papermill":{"duration":11.921201,"end_time":"2025-05-26T10:58:09.571539","exception":false,"start_time":"2025-05-26T10:57:57.650338","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":1},{"id":"5192e6a9","cell_type":"markdown","source":"### Wandb utility code","metadata":{}},{"id":"47a349c3","cell_type":"code","source":"user_secrets = UserSecretsClient()\nkey = user_secrets.get_secret('wandb-api-key')\n\nwandb.login(key=key)","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:22.659691Z","iopub.execute_input":"2025-06-10T08:33:22.660090Z","iopub.status.idle":"2025-06-10T08:33:28.945709Z","shell.execute_reply.started":"2025-06-10T08:33:22.660065Z","shell.execute_reply":"2025-06-10T08:33:28.945171Z"},"papermill":{"duration":1.036547,"end_time":"2025-05-26T10:58:10.611567","exception":false,"start_time":"2025-05-26T10:58:09.575020","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"\u001b[34m\u001b[1mwandb\u001b[0m: Using wandb-core as the SDK backend.  Please refer to https://wandb.me/wandb-core for more information.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m If you're specifying your api key in code, ensure this code is not shared publicly.\n\u001b[34m\u001b[1mwandb\u001b[0m: \u001b[33mWARNING\u001b[0m Consider setting the WANDB_API_KEY environment variable, or running `wandb login` from the command line.\n\u001b[34m\u001b[1mwandb\u001b[0m: No netrc file found, creating one.\n\u001b[34m\u001b[1mwandb\u001b[0m: Appending key for api.wandb.ai to your netrc file: /root/.netrc\n\u001b[34m\u001b[1mwandb\u001b[0m: Currently logged in as: \u001b[33mfrancescogiannuzzo2002-fg\u001b[0m (\u001b[33mmiriam-lamari2-eurecom\u001b[0m) to \u001b[32mhttps://api.wandb.ai\u001b[0m. Use \u001b[1m`wandb login --relogin`\u001b[0m to force relogin\n","output_type":"stream"},{"execution_count":2,"output_type":"execute_result","data":{"text/plain":"True"},"metadata":{}}],"execution_count":2},{"id":"554a69dc","cell_type":"markdown","source":"## Minibatches ","metadata":{"papermill":{"duration":0.00392,"end_time":"2025-05-26T10:58:10.619684","exception":false,"start_time":"2025-05-26T10:58:10.615764","status":"completed"},"tags":[]}},{"id":"223640be","cell_type":"code","source":"def minibatch_weight(batch_idx: int, num_batches: int) -> float:\n    return 2 ** (num_batches - batch_idx) / (2 ** num_batches - 1) # definition of pi_i","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:28.946548Z","iopub.execute_input":"2025-06-10T08:33:28.946902Z","iopub.status.idle":"2025-06-10T08:33:28.950762Z","shell.execute_reply.started":"2025-06-10T08:33:28.946880Z","shell.execute_reply":"2025-06-10T08:33:28.950028Z"},"papermill":{"duration":0.009609,"end_time":"2025-05-26T10:58:10.633024","exception":false,"start_time":"2025-05-26T10:58:10.623415","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":3},{"id":"157b16cb","cell_type":"markdown","source":"## Variational Approximation","metadata":{"papermill":{"duration":0.003647,"end_time":"2025-05-26T10:58:10.640662","exception":false,"start_time":"2025-05-26T10:58:10.637015","status":"completed"},"tags":[]}},{"id":"4b7b2881","cell_type":"code","source":"# Base class for BNN to enable certain behaviour\nclass BayesianModule(nn.Module):\n\n    def __init__(self):\n        super().__init__()\n\n    def kld(self, *args):\n        raise NotImplementedError('BayesianModule::kld()')\n\n\n# Variational approximator for Bayesian Neural Networks\ndef variational_approximator(model: nn.Module) -> nn.Module:\n\n    def kl_divergence(self) -> Tensor:\n        kl = 0\n        for module in self.modules():\n            if isinstance(module, BayesianModule):\n                kl += module.kl_divergence\n\n        return kl\n\n    def elbo(self, inputs: Tensor, targets: Tensor, criterion: Any, n_samples: int, w_complexity: Optional[float] = 1.0) -> Tensor:\n        loss = 0\n        for _ in range(n_samples):\n            outputs = self(inputs)\n            loss += criterion(outputs, targets)\n            loss += self.kl_divergence() * w_complexity\n\n        return loss / n_samples\n\n    # include `kl_divergence` function to the model\n    setattr(model, 'kl_divergence', kl_divergence)\n\n    # include `elbo` function to the model\n    setattr(model, 'elbo', elbo)\n\n    return model\n","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:28.952520Z","iopub.execute_input":"2025-06-10T08:33:28.952709Z","iopub.status.idle":"2025-06-10T08:33:28.968339Z","shell.execute_reply.started":"2025-06-10T08:33:28.952693Z","shell.execute_reply":"2025-06-10T08:33:28.967641Z"},"papermill":{"duration":0.012044,"end_time":"2025-05-26T10:58:10.656487","exception":false,"start_time":"2025-05-26T10:58:10.644443","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":4},{"id":"30e6c319","cell_type":"markdown","source":"## Scale Mixture Prior","metadata":{"papermill":{"duration":0.003589,"end_time":"2025-05-26T10:58:10.663915","exception":false,"start_time":"2025-05-26T10:58:10.660326","status":"completed"},"tags":[]}},{"id":"834c2b8f","cell_type":"code","source":"# Scale Mixture Prior for Bayesian Neural Networks\nclass ScaleMixture(nn.Module):\n    def __init__(self, pi: float, sigma1: float, sigma2: float) -> None:\n        super().__init__()\n\n        self.pi = pi\n        self.sigma1 = sigma1\n        self.sigma2 = sigma2\n\n        self.normal1 = torch.distributions.Normal(0, sigma1)\n        self.normal2 = torch.distributions.Normal(0, sigma2)\n\n    def log_prior(self, w: Tensor) -> Tensor:\n        likelihood_n1 = torch.exp(self.normal1.log_prob(w))\n        likelihood_n2 = torch.exp(self.normal2.log_prob(w))\n\n        p_scalemixture = self.pi * likelihood_n1 + (1 - self.pi) * likelihood_n2\n\n        log_prob = torch.log(p_scalemixture).sum()\n\n        return log_prob","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:28.968924Z","iopub.execute_input":"2025-06-10T08:33:28.969091Z","iopub.status.idle":"2025-06-10T08:33:28.983477Z","shell.execute_reply.started":"2025-06-10T08:33:28.969076Z","shell.execute_reply":"2025-06-10T08:33:28.982756Z"},"papermill":{"duration":0.012498,"end_time":"2025-05-26T10:58:10.680201","exception":false,"start_time":"2025-05-26T10:58:10.667703","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":5},{"id":"0dc45a1b","cell_type":"markdown","source":"### Variant: log-sum-exp rather than log","metadata":{}},{"id":"620b3341","cell_type":"code","source":"# Scale Mixture Prior for Bayesian Neural Networks\nclass ScaleMixture(nn.Module):\n    def __init__(self, pi: float, sigma1: float, sigma2: float) -> None:\n        super().__init__()\n        self.pi = pi\n        self.sigma1 = sigma1\n        self.sigma2 = sigma2\n\n        self.normal1 = torch.distributions.Normal(0, sigma1)\n        self.normal2 = torch.distributions.Normal(0, sigma2)\n\n    def log_prior(self, w: Tensor) -> Tensor:\n        log_prob_n1 = self.normal1.log_prob(w)\n        log_prob_n2 = self.normal2.log_prob(w)\n    \n        pi = torch.tensor(self.pi, device=w.device)\n        log_mix1 = torch.log(pi) + log_prob_n1\n        log_mix2 = torch.log(1.0 - pi) + log_prob_n2\n    \n        # Stable log-sum-exp over the two components\n        log_prob = torch.logsumexp(torch.stack([log_mix1, log_mix2]), dim=0).sum()\n        return log_prob\n","metadata":{"trusted":true,"execution":{"iopub.status.busy":"2025-06-10T08:33:28.984165Z","iopub.execute_input":"2025-06-10T08:33:28.984414Z","iopub.status.idle":"2025-06-10T08:33:29.000543Z","shell.execute_reply.started":"2025-06-10T08:33:28.984394Z","shell.execute_reply":"2025-06-10T08:33:28.999900Z"}},"outputs":[],"execution_count":6},{"id":"41977ea9","cell_type":"markdown","source":"## Gaussian Variational Inference","metadata":{"papermill":{"duration":0.003672,"end_time":"2025-05-26T10:58:10.687713","exception":false,"start_time":"2025-05-26T10:58:10.684041","status":"completed"},"tags":[]}},{"id":"e2a0431d","cell_type":"code","source":"# Gaussian Variational Approximation for Bayesian Neural Networks\nclass GaussianVariational(nn.Module):\n    def __init__(self, mu: Tensor, rho: Tensor) -> None:\n        super().__init__()\n\n        self.mu = nn.Parameter(mu)\n        self.rho = nn.Parameter(rho)\n\n        self.w = None\n        self.sigma = None\n\n        self.normal = torch.distributions.Normal(0, 1)\n\n    def sample(self) -> Tensor:\n        device = self.mu.device\n        epsilon = self.normal.sample(self.mu.size()).to(device)\n        self.sigma = torch.log(1 + torch.exp(self.rho)).to(device)\n        self.w = self.mu + self.sigma * epsilon\n        return self.w\n\n    def log_posterior(self) -> Tensor:\n        if self.w is None:\n            raise ValueError('self.w must have a value.')\n\n        log_const = np.log(np.sqrt(2 * np.pi))\n        log_exp = ((self.w - self.mu) ** 2) / (2 * self.sigma ** 2)\n        log_posterior = -log_const - torch.log(self.sigma) - log_exp\n\n        return log_posterior.sum()","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:29.001110Z","iopub.execute_input":"2025-06-10T08:33:29.001319Z","iopub.status.idle":"2025-06-10T08:33:29.015139Z","shell.execute_reply.started":"2025-06-10T08:33:29.001303Z","shell.execute_reply":"2025-06-10T08:33:29.014478Z"},"papermill":{"duration":0.013902,"end_time":"2025-05-26T10:58:10.705426","exception":false,"start_time":"2025-05-26T10:58:10.691524","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":7},{"id":"f644a1d6","cell_type":"markdown","source":"## Bayesian Linear Layer ##","metadata":{"papermill":{"duration":0.003639,"end_time":"2025-05-26T10:58:10.712942","exception":false,"start_time":"2025-05-26T10:58:10.709303","status":"completed"},"tags":[]}},{"id":"567f7ea3","cell_type":"code","source":"# Bayesian Linear Layer\nclass BayesLinear(BayesianModule):\n\n    def __init__(self,\n                 in_features: int,\n                 out_features: int,\n                 prior_pi: Optional[float] = 0.5,\n                 prior_sigma1: Optional[float] = 1.0,\n                 prior_sigma2: Optional[float] = 0.0025) -> None:\n\n        super().__init__()\n\n        w_mu = torch.empty(out_features, in_features).uniform_(-0.2, 0.2)\n        w_rho = torch.empty(out_features, in_features).uniform_(-5.0, -4.0)\n\n        bias_mu = torch.empty(out_features).uniform_(-0.2, 0.2)\n        bias_rho = torch.empty(out_features).uniform_(-5.0, -4.0)\n\n        self.w_posterior = GaussianVariational(w_mu, w_rho)\n        self.bias_posterior = GaussianVariational(bias_mu, bias_rho)\n\n        self.w_prior = ScaleMixture(prior_pi, prior_sigma1, prior_sigma2)\n        self.bias_prior = ScaleMixture(prior_pi, prior_sigma1, prior_sigma2)\n\n        self.kl_divergence = 0.0\n\n    def kld(self, log_prior: Tensor, log_posterior: Tensor) -> Tensor:\n        return log_posterior - log_prior\n\n    def forward(self, x: Tensor) -> Tensor:\n\n        w = self.w_posterior.sample()\n        b = self.bias_posterior.sample()\n\n        w_log_prior = self.w_prior.log_prior(w)\n        b_log_prior = self.bias_prior.log_prior(b)\n\n        w_log_posterior = self.w_posterior.log_posterior()\n        b_log_posterior = self.bias_posterior.log_posterior()\n\n        total_log_prior = w_log_prior + b_log_prior\n        total_log_posterior = w_log_posterior + b_log_posterior\n        self.kl_divergence = self.kld(total_log_prior, total_log_posterior)\n\n        return F.linear(x, w, b)","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:29.015859Z","iopub.execute_input":"2025-06-10T08:33:29.016075Z","iopub.status.idle":"2025-06-10T08:33:29.032861Z","shell.execute_reply.started":"2025-06-10T08:33:29.016053Z","shell.execute_reply":"2025-06-10T08:33:29.032161Z"},"papermill":{"duration":0.013667,"end_time":"2025-05-26T10:58:10.730256","exception":false,"start_time":"2025-05-26T10:58:10.716589","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":8},{"id":"7b230f35","cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nkwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}\n\n# define transforms\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:29.033499Z","iopub.execute_input":"2025-06-10T08:33:29.033711Z","iopub.status.idle":"2025-06-10T08:33:29.105775Z","shell.execute_reply.started":"2025-06-10T08:33:29.033696Z","shell.execute_reply":"2025-06-10T08:33:29.105001Z"},"papermill":{"duration":0.064333,"end_time":"2025-05-26T10:58:10.798409","exception":false,"start_time":"2025-05-26T10:58:10.734076","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":9},{"id":"d7a1ed17-d642-43cf-b13a-93e18dab6242","cell_type":"markdown","source":"### Load data for tuning","metadata":{}},{"id":"f4a6fe6d","cell_type":"code","source":"\"\"\"\n\nfull_trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n\n#train val split\n\ntrain_size = 50000\nval_size = 10000\ntrainset, valset = random_split(full_trainset, [train_size, val_size])\n\nkwargs = {'shuffle': True, 'num_workers': 2, 'pin_memory': True}\ntrainloader = DataLoader(trainset, batch_size=128, **kwargs)\nvalloader = DataLoader(valset, batch_size=128, **kwargs)\n\ntestset = datasets.MNIST('./data', train=False, download=True, transform=transform)\ntestloader = DataLoader(testset, batch_size=128, **kwargs)\n\n\"\"\"","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:29.107626Z","iopub.execute_input":"2025-06-10T08:33:29.107863Z","iopub.status.idle":"2025-06-10T08:33:29.121942Z","shell.execute_reply.started":"2025-06-10T08:33:29.107839Z","shell.execute_reply":"2025-06-10T08:33:29.121221Z"},"papermill":{"duration":0.009309,"end_time":"2025-05-26T10:58:10.812040","exception":false,"start_time":"2025-05-26T10:58:10.802731","status":"completed"},"tags":[],"trusted":true},"outputs":[{"execution_count":10,"output_type":"execute_result","data":{"text/plain":"\"\\n\\nfull_trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\\n\\n#train val split\\n\\ntrain_size = 50000\\nval_size = 10000\\ntrainset, valset = random_split(full_trainset, [train_size, val_size])\\n\\nkwargs = {'shuffle': True, 'num_workers': 2, 'pin_memory': True}\\ntrainloader = DataLoader(trainset, batch_size=128, **kwargs)\\nvalloader = DataLoader(valset, batch_size=128, **kwargs)\\n\\ntestset = datasets.MNIST('./data', train=False, download=True, transform=transform)\\ntestloader = DataLoader(testset, batch_size=128, **kwargs)\\n\\n\""},"metadata":{}}],"execution_count":10},{"id":"1fcad877-6378-47df-b4b5-3876dc613d1b","cell_type":"markdown","source":"### Load data for train-test","metadata":{}},{"id":"94fcc9fa","cell_type":"code","source":"full_trainset = datasets.MNIST('./data', train=True, download=True, transform=transform)\n\n#train-test split\n\ntrainset = full_trainset\n\nkwargs = {'shuffle': True, 'num_workers': 2, 'pin_memory': True}\ntrainloader = DataLoader(trainset, batch_size=128, **kwargs)\n\ntestset = datasets.MNIST('./data', train=False, download=True, transform=transform)\ntestloader = DataLoader(testset, batch_size=128, **kwargs)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:29.122632Z","iopub.execute_input":"2025-06-10T08:33:29.122907Z","iopub.status.idle":"2025-06-10T08:33:32.962488Z","shell.execute_reply.started":"2025-06-10T08:33:29.122885Z","shell.execute_reply":"2025-06-10T08:33:32.961679Z"},"papermill":{"duration":9.842882,"end_time":"2025-05-26T10:58:20.658199","exception":false,"start_time":"2025-05-26T10:58:10.815317","status":"completed"},"tags":[],"trusted":true},"outputs":[{"name":"stderr","text":"100%|██████████| 9.91M/9.91M [00:00<00:00, 17.7MB/s]\n100%|██████████| 28.9k/28.9k [00:00<00:00, 478kB/s]\n100%|██████████| 1.65M/1.65M [00:00<00:00, 4.47MB/s]\n100%|██████████| 4.54k/4.54k [00:00<00:00, 7.01MB/s]\n","output_type":"stream"}],"execution_count":11},{"id":"489f1bac-5ea0-4294-bed5-2ad200818756","cell_type":"markdown","source":"### Define Train loop","metadata":{}},{"id":"04f82e8c","cell_type":"code","source":"def train_loop(learning_rate, prior_pi, prior_sigma1, prior_sigma2, epochs=25):\n    @variational_approximator\n    class BayesianNetwork(nn.Module):\n        def __init__(self, input_dim, output_dim):\n            super().__init__()\n            self.bl1 = BayesLinear(input_dim, 1200, prior_pi, prior_sigma1, prior_sigma2)\n            self.bl2 = BayesLinear(1200, 1200, prior_pi, prior_sigma1, prior_sigma2)\n            self.bl3 = BayesLinear(1200, output_dim, prior_pi, prior_sigma1, prior_sigma2)\n\n        def forward(self, x):\n            x = x.view(-1, 28 * 28)\n\n            x = F.relu(self.bl1(x))\n            x = F.relu(self.bl2(x))\n            x = self.bl3(x)\n\n            return x\n\n    model = BayesianNetwork(28 * 28, 10).to(device)\n\n    optimizer = torch.optim.Adam(model.parameters(), lr=learning_rate)\n    criterion = nn.CrossEntropyLoss(reduction='sum')\n\n\n    min_test_loss = np.Inf\n    for epoch in range(epochs):\n\n        train_loss = 0.0\n        val_loss = 0.0\n\n        model.train()\n        for batch_idx, (data, labels) in enumerate(trainloader):\n            data, labels = data.to(device), labels.to(device)\n\n            optimizer.zero_grad()\n\n            pi_weight = minibatch_weight(batch_idx=batch_idx, num_batches=128)\n\n            loss = model.elbo(\n                inputs=data,\n                targets=labels,\n                criterion=criterion,\n                n_samples=3,\n                w_complexity=pi_weight\n            )\n\n            train_loss += loss.item() * data.size(0)\n\n            loss.backward()\n            optimizer.step()\n\n        correct = 0\n        total = 0\n\n        model.eval()\n        with torch.no_grad():\n            for batch_idx, (data, labels) in enumerate(testloader):\n                data, labels = data.to(device), labels.to(device)\n\n                outputs = model(data)\n\n                pi_weight = minibatch_weight(batch_idx=batch_idx, num_batches=128)\n\n                loss = model.elbo(\n                    inputs=data,\n                    targets=labels,\n                    criterion=criterion,\n                    n_samples=3,\n                    w_complexity=pi_weight\n                )\n\n                val_loss += loss.item() * data.size(0)\n\n                probabilities = F.softmax(outputs)\n                _, predicted = torch.max(probabilities.data, 1)\n\n                total += labels.size(0)\n                correct += torch.eq(predicted, labels).sum().item()\n\n        accuracy_val = correct / total\n        train_loss /= len(trainloader.dataset)\n        val_loss /= len(testloader.dataset)\n\n        metrics = {'train_loss': train_loss, 'val_loss': val_loss, 'accuracy_val': accuracy_val, \"test_error_val\": (1 - accuracy_val)  }\n        wandb.log(metrics)\n","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:32.963722Z","iopub.execute_input":"2025-06-10T08:33:32.964006Z","iopub.status.idle":"2025-06-10T08:33:32.974196Z","shell.execute_reply.started":"2025-06-10T08:33:32.963981Z","shell.execute_reply":"2025-06-10T08:33:32.973544Z"},"papermill":{"duration":0.01627,"end_time":"2025-05-26T10:58:20.679523","exception":false,"start_time":"2025-05-26T10:58:20.663253","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":12},{"id":"2fdfa0fe","cell_type":"code","source":"def train_wrapper():\n\n    return train_loop(\n        learning_rate = wandb.config.learning_rate,\n        prior_pi = wandb.config.prior_pi,\n        prior_sigma1=wandb.config.prior_sigma1,\n        prior_sigma2=wandb.config.prior_sigma2\n    )","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:32.974923Z","iopub.execute_input":"2025-06-10T08:33:32.975155Z","iopub.status.idle":"2025-06-10T08:33:32.997670Z","shell.execute_reply.started":"2025-06-10T08:33:32.975140Z","shell.execute_reply":"2025-06-10T08:33:32.996950Z"},"papermill":{"duration":0.009523,"end_time":"2025-05-26T10:58:20.693574","exception":false,"start_time":"2025-05-26T10:58:20.684051","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":13},{"id":"bb346707","cell_type":"markdown","source":"### Tuning Hyperparamters","metadata":{"papermill":{"duration":0.004265,"end_time":"2025-05-26T10:58:20.702542","exception":false,"start_time":"2025-05-26T10:58:20.698277","status":"completed"},"tags":[]}},{"id":"620b5f2a","cell_type":"code","source":"sweep_configuration = {\n     \"method\": \"grid\",\n     \"metric\": {\"goal\": \"minimize\", \"name\": \"val_loss\"},\n     'name': \"sweep-BBB-Gaussian\",\n     \"parameters\": {\n         \"learning_rate\": {'values': [1e-3]},\n         \"prior_pi\": {'values': [0.25, 0.5, 0.75]},\n         \"prior_sigma1\": {'values': [1, math.exp(-1), math.exp(-2)]},\n         \"prior_sigma2\": {'values': [math.exp(-6), math.exp(-7), math.exp(-8)]},\n     },\n}\n\n#sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"Project-ASI\")\n#wandb.agent(sweep_id, function=train_wrapper);","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:32.998413Z","iopub.execute_input":"2025-06-10T08:33:32.998603Z","iopub.status.idle":"2025-06-10T08:33:33.014789Z","shell.execute_reply.started":"2025-06-10T08:33:32.998589Z","shell.execute_reply":"2025-06-10T08:33:33.014160Z"},"papermill":{"duration":0.010288,"end_time":"2025-05-26T10:58:20.717183","exception":false,"start_time":"2025-05-26T10:58:20.706895","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":14},{"id":"e8a91e51","cell_type":"code","source":"sweep_configuration = {\n     \"method\": \"grid\",\n     \"metric\": {\"goal\": \"minimize\", \"name\": \"val_loss\"},\n     'name': \"sweep-BBB-Gaussian\",\n     \"parameters\": {\n         \"learning_rate\": {'values': [1e-4]},\n         \"prior_pi\": {'values': [0.25, 0.5, 0.75]},\n         \"prior_sigma1\": {'values': [1, math.exp(-1), math.exp(-2)]},\n         \"prior_sigma2\": {'values': [math.exp(-6), math.exp(-7), math.exp(-8)]},\n     },\n}\n\n#sweep_id = wandb.sweep(sweep=sweep_configuration, project=\"Project-ASI\")\n#wandb.agent(sweep_id, function=train_wrapper);","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:33.015511Z","iopub.execute_input":"2025-06-10T08:33:33.015724Z","iopub.status.idle":"2025-06-10T08:33:33.033691Z","shell.execute_reply.started":"2025-06-10T08:33:33.015706Z","shell.execute_reply":"2025-06-10T08:33:33.032999Z"},"papermill":{"duration":0.009627,"end_time":"2025-05-26T10:58:20.731383","exception":false,"start_time":"2025-05-26T10:58:20.721756","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":15},{"id":"19dcbdd3-9c7b-4ca3-b2ce-5b387e8632d6","cell_type":"markdown","source":"### Best Hyperparamters","metadata":{}},{"id":"6afd0d3f","cell_type":"code","source":"best_hyperparameters = {'learning_rate' : 1e-3, 'prior_pi' : 0.5, 'prior_sigma1' : 1.0, 'prior_sigma2' : math.exp(-7)}","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:33.034466Z","iopub.execute_input":"2025-06-10T08:33:33.034685Z","iopub.status.idle":"2025-06-10T08:33:33.047950Z","shell.execute_reply.started":"2025-06-10T08:33:33.034666Z","shell.execute_reply":"2025-06-10T08:33:33.047344Z"},"papermill":{"duration":0.009193,"end_time":"2025-05-26T10:58:20.745093","exception":false,"start_time":"2025-05-26T10:58:20.735900","status":"completed"},"tags":[],"trusted":true},"outputs":[],"execution_count":16},{"id":"fdf9ea42-6aba-401b-9a03-d89003a18e32","cell_type":"markdown","source":"### Train-Test Hyperparamters","metadata":{}},{"id":"c0471852","cell_type":"code","source":"wandb.init(project=\"Project-ASI\")\nwandb.run.log_code = False\n\ntrain_loop(\n    learning_rate = best_hyperparameters['learning_rate'],\n    prior_pi = best_hyperparameters['prior_pi'],\n    prior_sigma1 = best_hyperparameters['prior_sigma1'],\n    prior_sigma2 = best_hyperparameters['prior_sigma2'],\n    epochs = 200\n)","metadata":{"execution":{"iopub.status.busy":"2025-06-10T08:33:33.048621Z","iopub.execute_input":"2025-06-10T08:33:33.048850Z","iopub.status.idle":"2025-06-10T08:34:42.328087Z","shell.execute_reply.started":"2025-06-10T08:33:33.048832Z","shell.execute_reply":"2025-06-10T08:34:42.327365Z"},"papermill":{"duration":10656.287722,"end_time":"2025-05-26T13:55:57.037541","exception":false,"start_time":"2025-05-26T10:58:20.749819","status":"completed"},"tags":[],"trusted":true},"outputs":[{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Tracking run with wandb version 0.19.9"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Run data is saved locally in <code>/kaggle/working/wandb/run-20250610_083333-c5slo4vu</code>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":"Syncing run <strong><a href='https://wandb.ai/miriam-lamari2-eurecom/Project-ASI/runs/c5slo4vu' target=\"_blank\">dauntless-bird-189</a></strong> to <a href='https://wandb.ai/miriam-lamari2-eurecom/Project-ASI' target=\"_blank\">Weights & Biases</a> (<a href='https://wandb.me/developer-guide' target=\"_blank\">docs</a>)<br>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View project at <a href='https://wandb.ai/miriam-lamari2-eurecom/Project-ASI' target=\"_blank\">https://wandb.ai/miriam-lamari2-eurecom/Project-ASI</a>"},"metadata":{}},{"output_type":"display_data","data":{"text/plain":"<IPython.core.display.HTML object>","text/html":" View run at <a href='https://wandb.ai/miriam-lamari2-eurecom/Project-ASI/runs/c5slo4vu' target=\"_blank\">https://wandb.ai/miriam-lamari2-eurecom/Project-ASI/runs/c5slo4vu</a>"},"metadata":{}},{"name":"stderr","text":"/tmp/ipykernel_35/2225691380.py:74: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n  probabilities = F.softmax(outputs)\n","output_type":"stream"}],"execution_count":17}]}