{"metadata":{"kernelspec":{"language":"python","display_name":"Python 3","name":"python3"},"language_info":{"pygments_lexer":"ipython3","nbconvert_exporter":"python","version":"3.6.4","file_extension":".py","codemirror_mode":{"name":"ipython","version":3},"name":"python","mimetype":"text/x-python"},"kaggle":{"accelerator":"none","dataSources":[],"isInternetEnabled":true,"language":"python","sourceType":"notebook","isGpuEnabled":false}},"nbformat_minor":4,"nbformat":4,"cells":[{"cell_type":"code","source":"# This Python 3 environment comes with many helpful analytics libraries installed\n# It is defined by the kaggle/python Docker image: https://github.com/kaggle/docker-python\n# For example, here's several helpful packages to load\n\nimport numpy as np # linear algebra\nimport pandas as pd # data processing, CSV file I/O (e.g. pd.read_csv)\n\n# Input data files are available in the read-only \"../input/\" directory\n# For example, running this (by clicking run or pressing Shift+Enter) will list all files under the input directory\n\nimport os\nfor dirname, _, filenames in os.walk('/kaggle/input'):\n    for filename in filenames:\n        print(os.path.join(dirname, filename))\n\n# You can write up to 20GB to the current directory (/kaggle/working/) that gets preserved as output when you create a version using \"Save & Run All\" \n# You can also write temporary files to /kaggle/temp/, but they won't be saved outside of the current session","metadata":{"_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"import csv\n\nimport numpy as np\nimport torch.nn as nn\nimport torch.nn.functional as F\nimport torch.utils.data\nfrom torchvision import datasets\nfrom torchvision import transforms\nimport wandb\n\nfrom torchwu.bayes_linear import BayesLinear\nfrom torchwu.utils.minibatch_weighting import minibatch_weight\nfrom torchwu.utils.variational_approximator import variational_approximator\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"device = torch.device('cuda' if torch.cuda.is_available() else 'cpu')\nkwargs = {'num_workers': 1, 'pin_memory': True} if device == 'cuda' else {}\n\n# define transforms\ntransform = transforms.Compose([\n    transforms.ToTensor(),\n    transforms.Normalize((0.1307,), (0.3081,))\n])\n","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"# load / process data\ntrainset = datasets.MNIST('./data', train=True, download=True,transform=transform)\ntrainloader = torch.utils.data.DataLoader(trainset, batch_size=128, **kwargs)\n\ntestset = datasets.MNIST('./data', train=False, download=True, transform=transform)\ntestloader = torch.utils.data.DataLoader(testset, batch_size=128, **kwargs)","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"#@variational_approximator\nclass BayesianNetwork(nn.Module):\n    def __init__(self, input_dim, output_dim):\n        super().__init__()\n        self.bl1 = BayesLinear(input_dim, 1200)\n        self.bl2 = BayesLinear(1200, 1200)\n        self.bl3 = BayesLinear(1200, output_dim)\n\n    def forward(self, x):\n        x = x.view(-1, 28 * 28)\n\n        x = F.relu(self.bl1(x))\n        x = F.relu(self.bl2(x))\n        x = self.bl3(x)\n\n        return x","metadata":{"trusted":true},"outputs":[],"execution_count":null},{"cell_type":"code","source":"model = BayesianNetwork(28 * 28, 10).to(device)\noptimizer = torch.optim.Adam(model.parameters(), lr=1e-3)\ncriterion = nn.CrossEntropyLoss(reduction='sum')\n\n# prepare results file\nwith open('results.csv', 'w+', newline=\"\") as f_out:\n    writer = csv.writer(f_out, delimiter=',')\n    writer.writerow(['epoch', 'train_loss', 'test_loss', 'accuracy'])\n\nmin_test_loss = np.Inf\nfor epoch in range(500):\n\n    train_loss = 0.0\n    test_loss = 0.0\n\n    model.train()\n    for batch_idx, (data, labels) in enumerate(trainloader):\n        data, labels = data.to(device), labels.to(device)\n\n        optimizer.zero_grad()\n\n        pi_weight = minibatch_weight(batch_idx=batch_idx, num_batches=128)\n\n        loss = model.elbo(\n            inputs=data,\n            targets=labels,\n            criterion=criterion,\n            n_samples=3,\n            w_complexity=pi_weight\n        )\n\n        train_loss += loss.item() * data.size(0)\n\n        loss.backward()\n        optimizer.step()\n\n        if batch_idx % 1000 == 0:\n            print(f'Train Epoch: {epoch} '\n                  f'[{batch_idx * len(data):05}/{len(trainloader.dataset)} '\n                  f'({100 * batch_idx / len(trainloader.dataset):.2f}%)]'\n                  f'\\tLoss: {loss.item():.6f}')\n\n    correct = 0\n    total = 0\n\n    model.eval()\n    with torch.no_grad():\n        for batch_idx, (data, labels) in enumerate(testloader):\n            data, labels = data.to(device), labels.to(device)\n\n            outputs = model(data)\n\n            pi_weight = minibatch_weight(batch_idx=batch_idx, num_batches=128)\n\n            loss = model.elbo(\n                inputs=data,\n                targets=labels,\n                criterion=criterion,\n                n_samples=3,\n                w_complexity=pi_weight\n            )\n\n            test_loss += loss.item() * data.size(0)\n\n            probabilities = F.softmax(outputs)\n            _, predicted = torch.max(probabilities.data, 1)\n\n            total += labels.size(0)\n            correct += torch.eq(predicted, labels).sum().item()\n\n    accuracy = 100 * correct / total\n    train_loss /= len(trainloader.dataset)\n    test_loss /= len(testloader.dataset)\n\n    if test_loss < min_test_loss:\n        print('\\nValidation Loss Decreased: {:.6f} -> {:.6f}\\n'\n              ''.format(min_test_loss, test_loss))\n\n        min_test_loss = test_loss\n        torch.save(model.state_dict(), 'mnistBNN_checkpoint.pt')\n\n    _results = [epoch, train_loss, test_loss, accuracy]\n\n    print(f'Epoch: {epoch:03} | '\n          f'Train Loss: {train_loss:.3f} |'\n          f'Test Loss: {test_loss:.3f} |'\n          f'Accuracy: {accuracy:.3f} %\\n')\n\n    # write results to file\n    with open('results.csv', 'a', newline=\"\") as f_out:\n        writer = csv.writer(f_out, delimiter=',')\n        writer.writerow(_results)","metadata":{"trusted":true},"outputs":[],"execution_count":null}]}